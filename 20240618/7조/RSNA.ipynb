{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef1ee77",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-17T17:23:00.953514Z",
     "iopub.status.busy": "2024-06-17T17:23:00.952629Z",
     "iopub.status.idle": "2024-06-17T17:23:07.148822Z",
     "shell.execute_reply": "2024-06-17T17:23:07.147940Z"
    },
    "papermill": {
     "duration": 6.208219,
     "end_time": "2024-06-17T17:23:07.151145",
     "exception": false,
     "start_time": "2024-06-17T17:23:00.942926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pydicom as dicom\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "import pandas as pd\n",
    "\n",
    "import pydicom as dicom # dicom\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "# read data\n",
    "train_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/'\n",
    "\n",
    "train  = pd.read_csv(train_path + 'train.csv')\n",
    "label = pd.read_csv(train_path + 'train_label_coordinates.csv')\n",
    "train_desc  = pd.read_csv(train_path + 'train_series_descriptions.csv')\n",
    "test_desc   = pd.read_csv(train_path + 'test_series_descriptions.csv')\n",
    "sub         = pd.read_csv(train_path + 'sample_submission.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5baa203",
   "metadata": {
    "papermill": {
     "duration": 0.007182,
     "end_time": "2024-06-17T17:23:07.166073",
     "exception": false,
     "start_time": "2024-06-17T17:23:07.158891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Image Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95bad06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:23:07.182329Z",
     "iopub.status.busy": "2024-06-17T17:23:07.181478Z",
     "iopub.status.idle": "2024-06-17T17:23:59.611343Z",
     "shell.execute_reply": "2024-06-17T17:23:59.610374Z"
    },
    "papermill": {
     "duration": 52.441258,
     "end_time": "2024-06-17T17:23:59.614403",
     "exception": false,
     "start_time": "2024-06-17T17:23:07.173145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to generate image paths based on directory structure\n",
    "def generate_image_paths(df, data_dir):\n",
    "    image_paths = []\n",
    "    for study_id, series_id in zip(df['study_id'], df['series_id']):\n",
    "        study_dir = os.path.join(data_dir, str(study_id))\n",
    "        series_dir = os.path.join(study_dir, str(series_id))\n",
    "        images = os.listdir(series_dir)\n",
    "        image_paths.extend([os.path.join(series_dir, img) for img in images])\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "# Function to open and display DICOM images\n",
    "def display_dicom_images(image_paths):\n",
    "    plt.figure(figsize=(15, 5))  # Adjust figure size if needed\n",
    "    for i, path in enumerate(image_paths[:3]):\n",
    "        ds = pydicom.dcmread(path)\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.imshow(ds.pixel_array, cmap=plt.cm.bone)\n",
    "        plt.title(f\"Image {i+1}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Function to open and display DICOM images along with coordinates\n",
    "def display_dicom_with_coordinates(image_paths, label_df):\n",
    "    fig, axs = plt.subplots(1, len(image_paths), figsize=(18, 6))\n",
    "    \n",
    "    for idx, path in enumerate(image_paths):  # Display images\n",
    "        study_id = int(path.split('/')[-3])\n",
    "        series_id = int(path.split('/')[-2])\n",
    "        \n",
    "        # Filter label coordinates for the current study and series\n",
    "        filtered_labels = label_df[(label_df['study_id'] == study_id) & (label_df['series_id'] == series_id)]\n",
    "        \n",
    "        # Read DICOM image\n",
    "        ds = pydicom.dcmread(path)\n",
    "        \n",
    "        # Plot DICOM image\n",
    "        axs[idx].imshow(ds.pixel_array, cmap='gray')\n",
    "        axs[idx].set_title(f\"Study ID: {study_id}, Series ID: {series_id}\")\n",
    "        axs[idx].axis('off')\n",
    "        \n",
    "        # Plot coordinates\n",
    "        for _, row in filtered_labels.iterrows():\n",
    "            axs[idx].plot(row['x'], row['y'], 'ro', markersize=5)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load DICOM files from a folder\n",
    "def load_dicom_files(path_to_folder):\n",
    "    files = [os.path.join(path_to_folder, f) for f in os.listdir(path_to_folder) if f.endswith('.dcm')]\n",
    "    files.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('-')[-1]))\n",
    "    return files\n",
    "\n",
    "\n",
    "# Generate image paths for train and test data\n",
    "train_image_paths = generate_image_paths(train_desc, f'{train_path}/train_images')\n",
    "test_image_paths = generate_image_paths(test_desc, f'{train_path}/test_images')\n",
    "\n",
    "\n",
    "# Display the first three DICOM images\n",
    "#display_dicom_images(train_image_paths)\n",
    "\n",
    "# Display DICOM images with coordinates\n",
    "study_id = \"100206310\"\n",
    "study_folder = f'{train_path}/train_images/{study_id}'\n",
    "\n",
    "image_paths = []\n",
    "for series_folder in os.listdir(study_folder):\n",
    "    series_folder_path = os.path.join(study_folder, series_folder)\n",
    "    dicom_files = load_dicom_files(series_folder_path)\n",
    "    if dicom_files:\n",
    "        image_paths.append(dicom_files[0])  # Add the first image from each series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b732ae",
   "metadata": {
    "papermill": {
     "duration": 0.008957,
     "end_time": "2024-06-17T17:23:59.634375",
     "exception": false,
     "start_time": "2024-06-17T17:23:59.625418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Deata processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1c8e22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:23:59.654342Z",
     "iopub.status.busy": "2024-06-17T17:23:59.653872Z",
     "iopub.status.idle": "2024-06-17T17:24:21.381791Z",
     "shell.execute_reply": "2024-06-17T17:24:21.380805Z"
    },
    "papermill": {
     "duration": 21.739876,
     "end_time": "2024-06-17T17:24:21.384079",
     "exception": false,
     "start_time": "2024-06-17T17:23:59.644203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class counts:\n",
      " severity\n",
      "Normal/Mild    37626\n",
      "Moderate        7950\n",
      "Severe          3081\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#################################################### Deata processing ###########################################################\n",
    "\n",
    "# Define function to reshape a single row of the DataFrame\n",
    "def reshape_row(row):\n",
    "    data = {'study_id': [], 'condition': [], 'level': [], 'severity': []}\n",
    "    \n",
    "    for column, value in row.items():\n",
    "        if column not in ['study_id', 'series_id', 'instance_number', 'x', 'y', 'series_description']:\n",
    "            parts = column.split('_')\n",
    "            condition = ' '.join([word.capitalize() for word in parts[:-2]])\n",
    "            level = parts[-2].capitalize() + '/' + parts[-1].capitalize()\n",
    "            data['study_id'].append(row['study_id'])\n",
    "            data['condition'].append(condition)\n",
    "            data['level'].append(level)\n",
    "            data['severity'].append(value)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Reshape the DataFrame for all rows\n",
    "new_train_df = pd.concat([reshape_row(row) for _, row in train.iterrows()], ignore_index=True)\n",
    "\n",
    "# Merge the dataframes on the common columns\n",
    "merged_df = pd.merge(new_train_df, label, on=['study_id', 'condition', 'level'], how='inner')\n",
    "\n",
    "# Merge the dataframes on the common column 'series_id'\n",
    "final_merged_df = pd.merge(merged_df, train_desc, on='series_id', how='inner')\n",
    "\n",
    "# Merge the dataframes on the common column 'series_id'\n",
    "final_merged_df = pd.merge(merged_df, train_desc, on=['series_id','study_id'], how='inner')\n",
    "# Display the first few rows of the final merged dataframe\n",
    "\n",
    "# Create the row_id column\n",
    "final_merged_df['row_id'] = (\n",
    "    final_merged_df['study_id'].astype(str) + '_' +\n",
    "    final_merged_df['condition'].str.lower().str.replace(' ', '_') + '_' +\n",
    "    final_merged_df['level'].str.lower().str.replace('/', '_')\n",
    ")\n",
    "\n",
    "# Create the image_path column\n",
    "final_merged_df['image_path'] = (\n",
    "    f'{train_path}/train_images/' + \n",
    "    final_merged_df['study_id'].astype(str) + '/' +\n",
    "    final_merged_df['series_id'].astype(str) + '/' +\n",
    "    final_merged_df['instance_number'].astype(str) + '.dcm'\n",
    ")\n",
    "\n",
    "# Define the base path for test images\n",
    "base_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/'\n",
    "\n",
    "# Function to get image paths for a series\n",
    "def get_image_paths(row):\n",
    "    series_path = os.path.join(base_path, str(row['study_id']), str(row['series_id']))\n",
    "    if os.path.exists(series_path):\n",
    "        return [os.path.join(series_path, f) for f in os.listdir(series_path) if os.path.isfile(os.path.join(series_path, f))]\n",
    "    return []\n",
    "\n",
    "# Mapping of series_description to conditions\n",
    "condition_mapping = {\n",
    "    'Sagittal T1': {'left': 'left_neural_foraminal_narrowing', 'right': 'right_neural_foraminal_narrowing'},\n",
    "    'Axial T2': {'left': 'left_subarticular_stenosis', 'right': 'right_subarticular_stenosis'},\n",
    "    'Sagittal T2/STIR': 'spinal_canal_stenosis'\n",
    "}\n",
    "\n",
    "# Create a list to store the expanded rows\n",
    "expanded_rows = []\n",
    "\n",
    "# Expand the dataframe by adding new rows for each file path\n",
    "for index, row in test_desc.iterrows():\n",
    "    image_paths = get_image_paths(row)\n",
    "    conditions = condition_mapping.get(row['series_description'], {})\n",
    "    if isinstance(conditions, str):  # Single condition\n",
    "        conditions = {'left': conditions, 'right': conditions}\n",
    "    for side, condition in conditions.items():\n",
    "        for image_path in image_paths:\n",
    "            expanded_rows.append({\n",
    "                'study_id': row['study_id'],\n",
    "                'series_id': row['series_id'],\n",
    "                'series_description': row['series_description'],\n",
    "                'image_path': image_path,\n",
    "                'condition': condition,\n",
    "                'row_id': f\"{row['study_id']}_{condition}\"\n",
    "            })\n",
    "\n",
    "# Create a new dataframe from the expanded rows\n",
    "expanded_test_desc = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Train_data and test_data\n",
    "train_data = final_merged_df\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Define a function to check if a path exists\n",
    "def check_exists(path):\n",
    "    return os.path.exists(path)\n",
    "\n",
    "# Define a function to check if a study ID directory exists\n",
    "def check_study_id(row):\n",
    "    study_id = row['study_id']\n",
    "    path = f'{train_path}/train_images/{study_id}'\n",
    "    return check_exists(path)\n",
    "\n",
    "# Define a function to check if a series ID directory exists\n",
    "def check_series_id(row):\n",
    "    study_id = row['study_id']\n",
    "    series_id = row['series_id']\n",
    "    path = f'{train_path}/train_images/{study_id}/{series_id}'\n",
    "    return check_exists(path)\n",
    "\n",
    "# Define a function to check if an image file exists\n",
    "def check_image_exists(row):\n",
    "    image_path = row['image_path']\n",
    "    return check_exists(image_path)\n",
    "\n",
    "# Apply the functions to the train_data dataframe\n",
    "train_data['study_id_exists'] = train_data.apply(check_study_id, axis=1)\n",
    "train_data['series_id_exists'] = train_data.apply(check_series_id, axis=1)\n",
    "train_data['image_exists'] = train_data.apply(check_image_exists, axis=1)\n",
    "\n",
    "# Filter train_data\n",
    "train_data = train_data[(train_data['study_id_exists']) & (train_data['series_id_exists']) & (train_data['image_exists'])]\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "\n",
    "# resampling\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "class_counts = train_data['severity'].value_counts()\n",
    "print(\"Original class counts:\\n\", class_counts)\n",
    "\n",
    "# 최대 클래스 수\n",
    "max_count = class_counts.max()\n",
    "\n",
    "# 각 클래스의 데이터를 균형 맞추기 위해 리샘플링\n",
    "balanced_data = pd.DataFrame()\n",
    "\n",
    "for severity in class_counts.index:\n",
    "    class_data = train_data[train_data['severity'] == severity]\n",
    "    if len(class_data) < max_count:\n",
    "\n",
    "        class_data = resample(class_data, replace=True, n_samples=max_count, random_state=42)\n",
    "    balanced_data = pd.concat([balanced_data, class_data])\n",
    "\n",
    "train_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f5ccb",
   "metadata": {
    "papermill": {
     "duration": 0.007154,
     "end_time": "2024-06-17T17:24:21.398853",
     "exception": false,
     "start_time": "2024-06-17T17:24:21.391699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e83d408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:24:21.415313Z",
     "iopub.status.busy": "2024-06-17T17:24:21.414732Z",
     "iopub.status.idle": "2024-06-17T17:24:21.981222Z",
     "shell.execute_reply": "2024-06-17T17:24:21.980437Z"
    },
    "papermill": {
     "duration": 0.577401,
     "end_time": "2024-06-17T17:24:21.983521",
     "exception": false,
     "start_time": "2024-06-17T17:24:21.406120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################################### Loading Data ###########################################################\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def load_dicom(path):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        # self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.dataframe['image_path'][index]\n",
    "        image = load_dicom(image_path)  # Define this function to load your DICOM images\n",
    "        label = self.dataframe['severity'][index]\n",
    "\n",
    "        # image가 None인 경우 처리\n",
    "        if image is None:\n",
    "            # 예를 들어, None 대신 검정색 이미지 반환\n",
    "            image = np.zeros((256, 256), dtype=np.uint8)  # 또는 이미지 크기에 맞게 설정\n",
    "        \n",
    "        # image proccessing\n",
    "        image = (image * 255).astype(np.uint8)  # Convert back to uint8 for PIL\n",
    "        \n",
    "        image = Image.fromarray(image)  # Convert to PIL Image\n",
    "        # Convert back to numpy array\n",
    "        image = np.array(image)\n",
    "        # image crop\n",
    "        x = round(self.dataframe['x'][index])\n",
    "        y = round(self.dataframe['y'][index])\n",
    "        \n",
    "        gap_x = round(image.shape[0] / 10)\n",
    "        gap_y = round(image.shape[1] / 10)\n",
    "\n",
    "        # 이미지 크롭 범위가 유효한지 확인\n",
    "        if y-gap_y < 0 or y+gap_y > image.shape[0] or x-gap_x < 0 or x+gap_x > image.shape[1]:\n",
    "            image = np.zeros((256, 256), dtype=np.uint8)  # 유효하지 않으면 검정색 이미지 반환\n",
    "        else:\n",
    "            image = image[y-gap_y : y+gap_y, x-gap_x : x+gap_x]\n",
    "\n",
    "        image = cv2.equalizeHist(image)\n",
    "\n",
    "        color_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        image = Image.fromarray(image).resize((224, 224), Image.BILINEAR)\n",
    "        image = np.array(image)\n",
    "        \n",
    "        # Convert to 3 channels (RGB)\n",
    "        image = np.stack([image] * 3, axis=-1) if image.ndim == 2 else image\n",
    "\n",
    "        image = image.transpose((2, 0, 1))  # Change to (C, H, W) format\n",
    "        image = torch.tensor(image, dtype=torch.float32) / 255.0  # Convert to tensor and normalize\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Function to create datasets and dataloaders for each series description\n",
    "def create_datasets_and_loaders(df, series_description, batch_size=20):\n",
    "    filtered_df = df[df['series_description'] == series_description]\n",
    "    \n",
    "    train_df, val_df = train_test_split(filtered_df, test_size=0.2, random_state=42)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "    train_dataset = CustomDataset(train_df)\n",
    "    val_dataset = CustomDataset(val_df)\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return trainloader, valloader, len(train_df), len(val_df)\n",
    "\n",
    "# Create dataloaders for each series description\n",
    "dataloaders = {}\n",
    "lengths = {}\n",
    "\n",
    "trainloader_t1, valloader_t1, len_train_t1, len_val_t1 = create_datasets_and_loaders(train_data, 'Sagittal T1')\n",
    "trainloader_t2, valloader_t2, len_train_t2, len_val_t2 = create_datasets_and_loaders(train_data, 'Axial T2')\n",
    "trainloader_t2stir, valloader_t2stir, len_train_t2stir, len_val_t2stir = create_datasets_and_loaders(train_data, 'Sagittal T2/STIR')\n",
    "\n",
    "dataloaders['Sagittal T1'] = (trainloader_t1, valloader_t1)\n",
    "dataloaders['Axial T2'] = (trainloader_t2, valloader_t2)\n",
    "dataloaders['Sagittal T2/STIR'] = (trainloader_t2stir, valloader_t2stir)\n",
    "\n",
    "lengths['Sagittal T1'] = (len_train_t1, len_val_t1)\n",
    "lengths['Axial T2'] = (len_train_t2, len_val_t2)\n",
    "lengths['Sagittal T2/STIR'] = (len_train_t2stir, len_val_t2stir)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize a batch of images\n",
    "def visualize_batch(dataloader):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(20, 5))\n",
    "    for i, (img, lbl) in enumerate(zip(images, labels)):\n",
    "        ax = axes[i]\n",
    "        img = img.permute(1, 2, 0)  # Convert to HWC for visualization\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Label: {lbl}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65caea60",
   "metadata": {
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-06-17T17:24:21.998114",
     "exception": false,
     "start_time": "2024-06-17T17:24:21.991063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Data Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f164ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:24:22.015559Z",
     "iopub.status.busy": "2024-06-17T17:24:22.014729Z",
     "iopub.status.idle": "2024-06-17T17:24:22.019108Z",
     "shell.execute_reply": "2024-06-17T17:24:22.018217Z"
    },
    "papermill": {
     "duration": 0.014713,
     "end_time": "2024-06-17T17:24:22.021127",
     "exception": false,
     "start_time": "2024-06-17T17:24:22.006414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################ Data Visulization ##############################################\n",
    "\n",
    "# # Visualize samples from each dataloader\n",
    "# print(\"Visualizing Sagittal T1 samples\")\n",
    "# visualize_batch(valloader_t1)\n",
    "# print(\"Visualizing Axial T2 samples\")\n",
    "# visualize_batch(trainloader_t2)\n",
    "# print(\"Visualizing Sagittal T2/STIR samples\")\n",
    "# visualize_batch(trainloader_t2stir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a35bb6",
   "metadata": {
    "papermill": {
     "duration": 0.007059,
     "end_time": "2024-06-17T17:24:22.035512",
     "exception": false,
     "start_time": "2024-06-17T17:24:22.028453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37efd2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:24:22.051694Z",
     "iopub.status.busy": "2024-06-17T17:24:22.051001Z",
     "iopub.status.idle": "2024-06-17T17:24:25.073899Z",
     "shell.execute_reply": "2024-06-17T17:24:25.073104Z"
    },
    "papermill": {
     "duration": 3.03356,
     "end_time": "2024-06-17T17:24:25.076246",
     "exception": false,
     "start_time": "2024-06-17T17:24:22.042686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "################################ Model ###########################################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes=3, pretrained_model_path=None):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.model = models.resnet18(weights=None)  # Pre-trained weights will be loaded manually\n",
    "        if pretrained_model_path:\n",
    "            self.model.load_state_dict(torch.load(pretrained_model_path))\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize models\n",
    "sagittal_t1_model = CustomResNet(num_classes=3, pretrained_model_path=\"/kaggle/input/resnet/resnet18-5c106cde.pth\").to(device)\n",
    "axial_t2_model = CustomResNet(num_classes=3, pretrained_model_path=\"/kaggle/input/resnet/resnet18-5c106cde.pth\").to(device)\n",
    "sagittal_t2stir_model = CustomResNet(num_classes=3, pretrained_model_path=\"/kaggle/input/resnet/resnet18-5c106cde.pth\").to(device)\n",
    "\n",
    "\n",
    "# Unfreeze all layers\n",
    "for param in sagittal_t1_model.model.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in axial_t2_model.model.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in sagittal_t2stir_model.model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Training parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize separate optimizers for each model with L2 regularization\n",
    "optimizer_sagittal_t1 = torch.optim.SGD(sagittal_t1_model.model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer_axial_t2 = torch.optim.SGD(axial_t2_model.model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer_sagittal_t2stir = torch.optim.SGD(sagittal_t2stir_model.model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "# Store the models and optimizers in dictionaries for easy access\n",
    "model_dics = {\n",
    "    'Sagittal T1': sagittal_t1_model,\n",
    "    'Axial T2': axial_t2_model,\n",
    "    'Sagittal T2/STIR': sagittal_t2stir_model,\n",
    "}\n",
    "\n",
    "optimizers = {\n",
    "    'Sagittal T1': optimizer_sagittal_t1,\n",
    "    'Axial T2': optimizer_axial_t2,\n",
    "    'Sagittal T2/STIR': optimizer_sagittal_t2stir,\n",
    "}\n",
    "\n",
    "trainable_params = sum(p.numel() for p in sagittal_t1_model.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c820f",
   "metadata": {
    "papermill": {
     "duration": 0.007153,
     "end_time": "2024-06-17T17:24:25.091240",
     "exception": false,
     "start_time": "2024-06-17T17:24:25.084087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78cb8626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:24:25.107656Z",
     "iopub.status.busy": "2024-06-17T17:24:25.107152Z",
     "iopub.status.idle": "2024-06-17T17:24:26.537616Z",
     "shell.execute_reply": "2024-06-17T17:24:26.536548Z"
    },
    "papermill": {
     "duration": 1.441228,
     "end_time": "2024-06-17T17:24:26.539831",
     "exception": false,
     "start_time": "2024-06-17T17:24:25.098603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load!\n",
      "load!\n",
      "load!\n"
     ]
    }
   ],
   "source": [
    "############################# Training ###################################################3\n",
    "\n",
    "label_map = {'Normal/Mild': 0, 'Moderate': 1, 'Severe': 2}\n",
    "\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 15\n",
    "\n",
    "scheduler_sagittal_t1 = torch.optim.lr_scheduler.StepLR(optimizer_sagittal_t1, step_size=7, gamma=0.1)\n",
    "scheduler_axial_t2 = torch.optim.lr_scheduler.StepLR(optimizer_axial_t2, step_size=7, gamma=0.1)\n",
    "scheduler_sagittal_t2stir = torch.optim.lr_scheduler.StepLR(optimizer_sagittal_t2stir, step_size=7, gamma=0.1)\n",
    "\n",
    "schedulers = {\n",
    "    'Sagittal T1': scheduler_sagittal_t1,\n",
    "    'Axial T2': scheduler_axial_t2,\n",
    "    'Sagittal T2/STIR': scheduler_sagittal_t2stir,\n",
    "}\n",
    "\n",
    "\n",
    "## This is pretrained model ##\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop for all models\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    for model_name, model in model_dics.items():\n",
    "        \n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        trainloader = dataloaders[model_name][0]\n",
    "        valloader = dataloaders[model_name][1]\n",
    "        optimizer = optimizers[model_name]\n",
    "        scheduler = schedulers[model_name]\n",
    "        \n",
    "        # Use tqdm to display progress\n",
    "        train_progress_bar = tqdm(trainloader, desc=f\"{model_name} Train\")\n",
    "        for images, labels in train_progress_bar:\n",
    "            labels = torch.tensor([label_map[label] for label in labels]).to(device)\n",
    "            images = images.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_predictions += torch.sum(preds == labels.data)\n",
    "            \n",
    "            # Update progress bar with loss and accuracy\n",
    "            train_progress_bar.set_postfix(loss=loss.item(), acc=correct_predictions.double() / len(trainloader.dataset))\n",
    "        \n",
    "        epoch_loss = running_loss / len(trainloader.dataset)\n",
    "        epoch_acc = correct_predictions.double() / len(trainloader.dataset)\n",
    "        \n",
    "        print(f\"{model_name} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        \n",
    "        # Use tqdm to display progress\n",
    "        val_progress_bar = tqdm(valloader, desc=f\"{model_name} Val\")\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_progress_bar:\n",
    "                labels = torch.tensor([label_map[label] for label in labels]).to(device)\n",
    "                images = images.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct_predictions += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # Update progress bar with loss and accuracy\n",
    "                val_progress_bar.set_postfix(loss=loss.item(), acc=val_correct_predictions.double() / len(valloader.dataset))\n",
    "        \n",
    "        val_loss = val_running_loss / len(valloader.dataset)\n",
    "        val_acc = val_correct_predictions.double() / len(valloader.dataset)\n",
    "        \n",
    "        print(f\"{model_name} Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "# load_dir = '/kaggle/input/pretrained-model'\n",
    "\n",
    "# for model_name, model in model_dics.items():\n",
    "#     modified_string = model_name.replace(' ', '_').replace('/', '_')\n",
    "#     load_path = os.path.join(load_dir, f\"resNet18_{modified_string}.pth\")\n",
    "#     if os.path.exists(load_path):\n",
    "#         model.load_state_dict(torch.load(load_path))\n",
    "#         model.eval()\n",
    "#         print(\"load!\")\n",
    "#     else:\n",
    "#         print(f\"Model file not found: {load_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b895a0d1",
   "metadata": {
    "papermill": {
     "duration": 0.00828,
     "end_time": "2024-06-17T17:24:26.556092",
     "exception": false,
     "start_time": "2024-06-17T17:24:26.547812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "key point model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff5458d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:24:26.572921Z",
     "iopub.status.busy": "2024-06-17T17:24:26.572585Z",
     "iopub.status.idle": "2024-06-17T17:24:26.710788Z",
     "shell.execute_reply": "2024-06-17T17:24:26.709784Z"
    },
    "papermill": {
     "duration": 0.149493,
     "end_time": "2024-06-17T17:24:26.713234",
     "exception": false,
     "start_time": "2024-06-17T17:24:26.563741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "###################################################################################################################\n",
    "######################################### key point model #########################################################\n",
    "\n",
    "# 데이터 프레임 변환\n",
    "df_pivot = label.pivot_table(index=['study_id', 'series_id', 'instance_number', 'condition'],\n",
    "                          columns='level',\n",
    "                          values=['x', 'y'],\n",
    "                          aggfunc='first').reset_index()\n",
    "\n",
    "# 컬럼 이름 재구성\n",
    "df_pivot.columns = ['_'.join(col).strip() for col in df_pivot.columns.values]\n",
    "\n",
    "# 컬럼 이름 보기 좋게 정리\n",
    "df_pivot.columns = [col.replace('_', ' ') if col != '' else col for col in df_pivot.columns]\n",
    "df_pivot.columns = [col.replace('  ', '_').strip() for col in df_pivot.columns]\n",
    "\n",
    "df_pivot.columns = df_pivot.columns.str.replace(' ', '_')\n",
    "\n",
    "merged_df = pd.merge(df_pivot, train_desc, on=['study_id', 'series_id'], how='left')\n",
    "\n",
    "# Create the image_path column\n",
    "merged_df['image_path'] = (\n",
    "    f'{train_path}/train_images/' + \n",
    "    merged_df['study_id'].astype(str) + '/' +\n",
    "    merged_df['series_id'].astype(str) + '/' +\n",
    "    merged_df['instance_number'].astype(str) + '.dcm'\n",
    ")\n",
    "\n",
    "# Train_data and test_data\n",
    "train_data = merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17bd313",
   "metadata": {
    "papermill": {
     "duration": 0.007454,
     "end_time": "2024-06-17T17:24:26.728600",
     "exception": false,
     "start_time": "2024-06-17T17:24:26.721146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6666b9a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:24:26.745296Z",
     "iopub.status.busy": "2024-06-17T17:24:26.744945Z",
     "iopub.status.idle": "2024-06-17T17:24:26.774895Z",
     "shell.execute_reply": "2024-06-17T17:24:26.774091Z"
    },
    "papermill": {
     "duration": 0.040793,
     "end_time": "2024-06-17T17:24:26.777050",
     "exception": false,
     "start_time": "2024-06-17T17:24:26.736257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################### Data processing ###########################################################\n",
    "\n",
    "\n",
    "train_data.columns = train_data.columns.str.strip().str.replace(' ', '_')\n",
    "\n",
    "x_cols = [col for col in train_data.columns if col.startswith('x_')]\n",
    "y_cols = [col for col in train_data.columns if col.startswith('y_')]\n",
    "\n",
    "grouped_df = train_data.groupby(['study_id', 'series_id', 'series_description'], as_index=False).agg(\n",
    "    {**{col: 'mean' for col in x_cols + y_cols}, 'image_path': 'first'})\n",
    "\n",
    "train_data = grouped_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e81c3e",
   "metadata": {
    "papermill": {
     "duration": 0.007489,
     "end_time": "2024-06-17T17:24:26.792441",
     "exception": false,
     "start_time": "2024-06-17T17:24:26.784952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be374b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:24:26.809421Z",
     "iopub.status.busy": "2024-06-17T17:24:26.809073Z",
     "iopub.status.idle": "2024-06-17T17:24:26.844459Z",
     "shell.execute_reply": "2024-06-17T17:24:26.843543Z"
    },
    "papermill": {
     "duration": 0.046507,
     "end_time": "2024-06-17T17:24:26.846554",
     "exception": false,
     "start_time": "2024-06-17T17:24:26.800047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################################### Loading Data ###########################################################\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset_keypoint(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        # self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.dataframe['image_path'][index]\n",
    "        image = load_dicom(image_path)  # Define this function to load your DICOM images\n",
    "\n",
    "        L1_L2 = (self.dataframe['x_L1/L2'][index] , self.dataframe['y_L1/L2'][index])\n",
    "        L2_L3 = (self.dataframe['x_L2/L3'][index] , self.dataframe['y_L2/L3'][index])\n",
    "        L3_L4 = (self.dataframe['x_L3/L4'][index] , self.dataframe['y_L3/L4'][index])\n",
    "        L4_L5 = (self.dataframe['x_L4/L5'][index] , self.dataframe['y_L4/L5'][index])\n",
    "        L5_S1 = (self.dataframe['x_L5/S1'][index] , self.dataframe['y_L5/S1'][index])\n",
    "\n",
    "\n",
    "\n",
    "        keypoints = [L1_L2, L2_L3, L3_L4, L4_L5, L5_S1]\n",
    "\n",
    "        if image is None:\n",
    "            # 예를 들어, None 대신 검정색 이미지 반환\n",
    "            image = np.zeros((256, 256), dtype=np.uint8)  # 또는 이미지 크기에 맞게 설정\n",
    "        \n",
    "        # image proccessing\n",
    "        image = (image * 255).astype(np.uint8)  # Convert back to uint8 for PIL\n",
    "        h, w = image.shape\n",
    "        image = cv2.equalizeHist(image)\n",
    "\n",
    "        image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "        keypoints_resized = [(x * 224 / w, y * 224 / h) for x, y in keypoints]\n",
    "\n",
    "        # Convert to 3 channels (RGB)\n",
    "        image = np.stack([image] * 3, axis=-1) if image.ndim == 2 else image\n",
    "\n",
    "        image = image.transpose((2, 0, 1))  # Change to (C, H, W) format\n",
    "        image = torch.tensor(image, dtype=torch.float32) / 255.0  # Convert to tensor and normalize\n",
    "        keypoints_resized = torch.tensor(keypoints_resized, dtype=torch.float32).view(-1)\n",
    "\n",
    "        return image, keypoints_resized\n",
    "\n",
    "# Function to create datasets and dataloaders for each series description\n",
    "def create_datasets_and_loaders_keypoint(df, series_description, batch_size=20):\n",
    "\n",
    "    filtered_df = df[df['series_description'] == series_description]\n",
    "    \n",
    "    train_df, val_df = train_test_split(filtered_df, test_size=0.2, random_state=42)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "    train_dataset = CustomDataset_keypoint(train_df)\n",
    "    val_dataset = CustomDataset_keypoint(val_df)\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return trainloader, valloader, len(train_df), len(val_df)\n",
    "\n",
    "# Create dataloaders for each series description\n",
    "dataloaders = {}\n",
    "lengths = {}\n",
    "\n",
    "trainloader_t1, valloader_t1, len_train_t1, len_val_t1 = create_datasets_and_loaders_keypoint(train_data, 'Sagittal T1')\n",
    "trainloader_t2, valloader_t2, len_train_t2, len_val_t2 = create_datasets_and_loaders_keypoint(train_data, 'Axial T2')\n",
    "trainloader_t2stir, valloader_t2stir, len_train_t2stir, len_val_t2stir = create_datasets_and_loaders_keypoint(train_data, 'Sagittal T2/STIR')\n",
    "\n",
    "dataloaders['Sagittal T1'] = (trainloader_t1, valloader_t1)\n",
    "dataloaders['Axial T2'] = (trainloader_t2, valloader_t2)\n",
    "dataloaders['Sagittal T2/STIR'] = (trainloader_t2stir, valloader_t2stir)\n",
    "\n",
    "lengths['Sagittal T1'] = (len_train_t1, len_val_t1)\n",
    "lengths['Axial T2'] = (len_train_t2, len_val_t2)\n",
    "lengths['Sagittal T2/STIR'] = (len_train_t2stir, len_val_t2stir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize a batch of images\n",
    "def visualize_batch(dataloader):\n",
    "    images, keypoints = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8665dee",
   "metadata": {
    "papermill": {
     "duration": 0.007492,
     "end_time": "2024-06-17T17:24:26.862294",
     "exception": false,
     "start_time": "2024-06-17T17:24:26.854802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03344f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:24:26.879303Z",
     "iopub.status.busy": "2024-06-17T17:24:26.878950Z",
     "iopub.status.idle": "2024-06-17T17:24:29.513017Z",
     "shell.execute_reply": "2024-06-17T17:24:29.512228Z"
    },
    "papermill": {
     "duration": 2.645264,
     "end_time": "2024-06-17T17:24:29.515271",
     "exception": false,
     "start_time": "2024-06-17T17:24:26.870007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################ Model ###########################################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class KeypointModel(nn.Module):\n",
    "    def __init__(self, num_keypoints=5, pretrained_model_path=None):\n",
    "        super(KeypointModel, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=None)  # Pre-trained weights will be loaded manually\n",
    "        if pretrained_model_path:\n",
    "            self.resnet.load_state_dict(torch.load(pretrained_model_path))\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_keypoints * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Initialize models\n",
    "sagittal_t1_model_keypoint = KeypointModel(num_keypoints=5, pretrained_model_path=\"/kaggle/input/resnet/resnet50.pth\").to(device)\n",
    "axial_t2_model_keypoint = KeypointModel(num_keypoints=5, pretrained_model_path=\"/kaggle/input/resnet/resnet50.pth\").to(device)\n",
    "sagittal_t2stir_model_keypoint = KeypointModel(num_keypoints=5, pretrained_model_path=\"/kaggle/input/resnet/resnet50.pth\").to(device)\n",
    "\n",
    "# Unfreeze all layers\n",
    "for param in sagittal_t1_model_keypoint.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in axial_t2_model_keypoint.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in sagittal_t2stir_model_keypoint.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Initialize separate optimizers for each model with L2 regularization\n",
    "optimizer_sagittal_t1_keypoint = torch.optim.SGD(sagittal_t1_model_keypoint.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "#optimizer_axial_t2 = torch.optim.SGD(axial_t2_model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer_axial_t2_keypoint = torch.optim.Adam(axial_t2_model_keypoint.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "optimizer_sagittal_t2stir_keypoint = torch.optim.SGD(sagittal_t2stir_model_keypoint.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "# Store the models and optimizers in dictionaries for easy access\n",
    "keypoints_models = {\n",
    "    'Sagittal T1': sagittal_t1_model_keypoint,\n",
    "    'Axial T2': axial_t2_model_keypoint,\n",
    "    'Sagittal T2/STIR': sagittal_t2stir_model_keypoint,\n",
    "}\n",
    "\n",
    "keypoints_optimizers = {\n",
    "    'Sagittal T1': optimizer_sagittal_t1_keypoint,\n",
    "    'Axial T2': optimizer_axial_t2_keypoint,\n",
    "    'Sagittal T2/STIR': optimizer_sagittal_t2stir_keypoint,\n",
    "}\n",
    "\n",
    "scheduler_sagittal_t1_keypoint = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_sagittal_t1_keypoint, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "scheduler_axial_t2_keypoint = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_axial_t2_keypoint, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "scheduler_sagittal_t2stir_keypoint = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_sagittal_t2stir_keypoint, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "keypoints_schedulers = {\n",
    "    'Sagittal T1': scheduler_sagittal_t1_keypoint,\n",
    "    'Axial T2': scheduler_axial_t2_keypoint,\n",
    "    'Sagittal T2/STIR': scheduler_sagittal_t2stir_keypoint,\n",
    "}\n",
    "\n",
    "trainable_params = sum(p.numel() for p in sagittal_t1_model_keypoint.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faec0c1",
   "metadata": {
    "papermill": {
     "duration": 0.007422,
     "end_time": "2024-06-17T17:24:29.530655",
     "exception": false,
     "start_time": "2024-06-17T17:24:29.523233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb61405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:24:29.547092Z",
     "iopub.status.busy": "2024-06-17T17:24:29.546792Z",
     "iopub.status.idle": "2024-06-17T17:24:32.390911Z",
     "shell.execute_reply": "2024-06-17T17:24:32.389936Z"
    },
    "papermill": {
     "duration": 2.855136,
     "end_time": "2024-06-17T17:24:32.393184",
     "exception": false,
     "start_time": "2024-06-17T17:24:29.538048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "load\n",
      "load\n"
     ]
    }
   ],
   "source": [
    "############################# Training ###################################################3\n",
    "\n",
    "\n",
    "# Training loop for all models\n",
    "num_epochs = 27\n",
    "criterion = nn.SmoothL1Loss() \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    for model_name, model in keypoints_models.items():\n",
    "        \n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        trainloader = dataloaders[model_name][0]\n",
    "        valloader = dataloaders[model_name][1]\n",
    "        optimizer = keypoints_optimizers[model_name]\n",
    "        scheduler = keypoints_schedulers[model_name]\n",
    "        \n",
    "        for images, keypoints in trainloader:\n",
    "            keypoints = keypoints.to(device)\n",
    "            images = images.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, keypoints)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(trainloader.dataset)\n",
    "        \n",
    "        print(f\"{model_name} Train Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, keypoints in valloader:\n",
    "                keypoints = keypoints.view(-1, 10).to(device)\n",
    "                images = images.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, keypoints)\n",
    "                \n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        val_loss = val_running_loss / len(valloader.dataset)\n",
    "        \n",
    "        print(f\"{model_name} Val Loss: {val_loss:.4f}\")\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "# load_dir = '/kaggle/input/pretrained-model'\n",
    "# os.makedirs(load_dir, exist_ok=True)\n",
    "\n",
    "# for model_name, model in keypoints_models.items():\n",
    "#     modified_string = model_name.replace(' ', '_').replace('/', '_')\n",
    "#     load_path = os.path.join(load_dir, f\"keypoints_resNet50_{modified_string}.pth\")\n",
    "#     model.load_state_dict(torch.load(load_path))\n",
    "#     print(\"load\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a16c60",
   "metadata": {
    "papermill": {
     "duration": 0.008051,
     "end_time": "2024-06-17T17:24:32.409734",
     "exception": false,
     "start_time": "2024-06-17T17:24:32.401683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a08dc55b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:24:32.427154Z",
     "iopub.status.busy": "2024-06-17T17:24:32.426837Z",
     "iopub.status.idle": "2024-06-17T17:24:40.630254Z",
     "shell.execute_reply": "2024-06-17T17:24:40.629312Z"
    },
    "papermill": {
     "duration": 8.215903,
     "end_time": "2024-06-17T17:24:40.633379",
     "exception": false,
     "start_time": "2024-06-17T17:24:32.417476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:08<00:00, 23.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             row_id  normal_mild  moderate  \\\n",
      "0    44036939_left_neural_foraminal_narrowing_l1_l2     0.400475  0.378718   \n",
      "1    44036939_left_neural_foraminal_narrowing_l2_l3     0.374593  0.281383   \n",
      "2    44036939_left_neural_foraminal_narrowing_l3_l4     0.054124  0.740683   \n",
      "3    44036939_left_neural_foraminal_narrowing_l4_l5     0.735425  0.097878   \n",
      "4    44036939_left_neural_foraminal_narrowing_l5_s1     0.090160  0.577792   \n",
      "5         44036939_left_subarticular_stenosis_l1_l2     0.503563  0.235323   \n",
      "6         44036939_left_subarticular_stenosis_l2_l3     0.464731  0.331803   \n",
      "7         44036939_left_subarticular_stenosis_l3_l4     0.189192  0.290436   \n",
      "8         44036939_left_subarticular_stenosis_l4_l5     0.421516  0.159078   \n",
      "9         44036939_left_subarticular_stenosis_l5_s1     0.637418  0.240354   \n",
      "10  44036939_right_neural_foraminal_narrowing_l1_l2     0.400475  0.378718   \n",
      "11  44036939_right_neural_foraminal_narrowing_l2_l3     0.374593  0.281383   \n",
      "12  44036939_right_neural_foraminal_narrowing_l3_l4     0.054124  0.740683   \n",
      "13  44036939_right_neural_foraminal_narrowing_l4_l5     0.735425  0.097878   \n",
      "14  44036939_right_neural_foraminal_narrowing_l5_s1     0.090160  0.577792   \n",
      "15       44036939_right_subarticular_stenosis_l1_l2     0.351288  0.450785   \n",
      "16       44036939_right_subarticular_stenosis_l2_l3     0.556404  0.021800   \n",
      "17       44036939_right_subarticular_stenosis_l3_l4     0.414155  0.373089   \n",
      "18       44036939_right_subarticular_stenosis_l4_l5     0.599525  0.202544   \n",
      "19       44036939_right_subarticular_stenosis_l5_s1     0.358151  0.198546   \n",
      "20             44036939_spinal_canal_stenosis_l1_l2     0.450987  0.388764   \n",
      "21             44036939_spinal_canal_stenosis_l2_l3     0.571943  0.051600   \n",
      "22             44036939_spinal_canal_stenosis_l3_l4     0.782304  0.209610   \n",
      "23             44036939_spinal_canal_stenosis_l4_l5     0.314271  0.002716   \n",
      "24             44036939_spinal_canal_stenosis_l5_s1     0.574366  0.040056   \n",
      "\n",
      "      severe  \n",
      "0   0.220807  \n",
      "1   0.344024  \n",
      "2   0.205193  \n",
      "3   0.166697  \n",
      "4   0.332048  \n",
      "5   0.261114  \n",
      "6   0.203467  \n",
      "7   0.520372  \n",
      "8   0.419406  \n",
      "9   0.122228  \n",
      "10  0.220807  \n",
      "11  0.344024  \n",
      "12  0.205193  \n",
      "13  0.166697  \n",
      "14  0.332048  \n",
      "15  0.197927  \n",
      "16  0.421796  \n",
      "17  0.212756  \n",
      "18  0.197931  \n",
      "19  0.443303  \n",
      "20  0.160249  \n",
      "21  0.376456  \n",
      "22  0.008086  \n",
      "23  0.683013  \n",
      "24  0.385578  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "###################################################################################################################\n",
    "###################################################################################################################\n",
    "\n",
    "##################################### Inference ##################################################################\n",
    "\n",
    "levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n",
    "\n",
    "# Function to update row_id with levels\n",
    "def update_row_id(row, levels):\n",
    "    level = levels[row.name % len(levels)]\n",
    "    return f\"{row['study_id']}_{row['condition']}_{level}\"\n",
    "\n",
    "def update_level(row, levels):\n",
    "    return levels[row.name % len(levels)]\n",
    "\n",
    "# Update row_id in expanded_test_desc to include levels\n",
    "expanded_test_desc['row_id'] = expanded_test_desc.apply(lambda row: update_row_id(row, levels), axis=1)\n",
    "expanded_test_desc['level'] = expanded_test_desc.apply(lambda row: update_level(row, levels), axis=1)\n",
    "\n",
    "# Define a custom test dataset class\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, dataframe, keypoints_models):\n",
    "        self.dataframe = dataframe\n",
    "        self.keypoints_models = keypoints_models\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.dataframe['image_path'][index]\n",
    "        image = load_dicom(image_path)  # Define this function to load your DICOM images\n",
    "\n",
    "        # image가 None인 경우 처리\n",
    "        if image is None:\n",
    "            # 예를 들어, None 대신 검정색 이미지 반환\n",
    "            image = np.zeros((256, 256), dtype=np.uint8)  # 또는 이미지 크기에 맞게 설정\n",
    "        \n",
    "        # image processing\n",
    "        image = (image * 255).astype(np.uint8)  # Convert back to uint8 for PIL\n",
    "        image = cv2.equalizeHist(image)\n",
    "        h, w = image.shape\n",
    "        resized_input_image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        r_img_c = resized_input_image\n",
    "\n",
    "        # Convert to 3 channels (RGB) for keypoints model\n",
    "        resized_input_image = np.stack([resized_input_image] * 3, axis=-1)\n",
    "        resized_input_image = resized_input_image.astype(np.float32) / 255.0  # 정규화\n",
    "        resized_input_image = np.transpose(resized_input_image, (2, 0, 1))  # HWC to CHW\n",
    "        resized_input_image = np.expand_dims(resized_input_image, axis=0)  # 배치 차원 추가\n",
    "        resized_input_image = torch.from_numpy(resized_input_image).to(device)   # 텐서로 변환\n",
    "\n",
    "        series_description = self.dataframe['series_description'][index]\n",
    "\n",
    "        keypoints_model = self.keypoints_models.get(series_description, None)\n",
    "        if keypoints_model is None:\n",
    "            raise ValueError(f\"Model for series_description '{series_description}' not found.\")\n",
    "        \n",
    "        keypoints_model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = keypoints_model(resized_input_image)\n",
    "        \n",
    "        outputs = outputs.squeeze().cpu().numpy()  # 결과를 numpy 배열로 변환\n",
    "        level = self.dataframe['level'][index]\n",
    "\n",
    "        levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n",
    "        level_index = levels.index(level)\n",
    "\n",
    "        x = outputs[2 * level_index]\n",
    "        y = outputs[2 * level_index + 1]\n",
    "\n",
    "        x = x * w / 224\n",
    "        y = y * h / 224\n",
    "\n",
    "        ########################## visulize ##########################\n",
    "        # x_list = outputs[: : 2]\n",
    "        # y_list = outputs[1 : : 2]\n",
    "        # x_list = x_list * w / 224\n",
    "        # y_list = y_list * h / 224\n",
    "\n",
    "        # img_c = image\n",
    "        # img_c = cv2.cvtColor(img_c, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # cv2.circle(img_c, (round(x_list[0]), round(y_list[0])), 5, (0, 0, 255), -1)\n",
    "        # cv2.circle(img_c, (round(x_list[1]), round(y_list[1])), 5, (0, 255, 0), -1)\n",
    "        # cv2.circle(img_c, (round(x_list[2]), round(y_list[2])), 5, (255, 0, 0), -1)\n",
    "        # cv2.circle(img_c, (round(x_list[3]), round(y_list[3])), 5, (0, 255, 255), -1)\n",
    "        # cv2.circle(img_c, (round(x_list[4]), round(y_list[4])), 5, (255, 0, 255), -1)\n",
    "        # cv2.imshow(\"img\", img_c)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        #############################################################\n",
    "        \n",
    "        gap_x = w / 10\n",
    "        gap_y = h / 10\n",
    "\n",
    "        # 이미지 크롭 범위가 유효한지 확인\n",
    "        if y-gap_y < 0 or y+gap_y > h or x-gap_x < 0 or x+gap_x > w:\n",
    "            image = np.zeros((256, 256), dtype=np.uint8)  # 유효하지 않으면 검정색 이미지 반환\n",
    "        else:\n",
    "            image = image[round(y-gap_y):round(y+gap_y), round(x-gap_x):round(x+gap_x)]\n",
    "\n",
    "        image = cv2.equalizeHist(image)\n",
    "\n",
    "        image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # cv2.imshow(\"image\", image)\n",
    "\n",
    "        # cv2.waitKey(0)\n",
    "        \n",
    "        # Convert to 3 channels (RGB)\n",
    "        image = np.stack([image] * 3, axis=-1) if image.ndim == 2 else image\n",
    "\n",
    "        image = image.transpose((2, 0, 1))  # Change to (C, H, W) format\n",
    "        image = torch.tensor(image, dtype=torch.float32) / 255.0  # Convert to tensor and normalize\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "# Create a test dataset and dataloader\n",
    "test_dataset = TestDataset(expanded_test_desc, keypoints_models)\n",
    "testloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# Function to get the model based on series_description\n",
    "def get_model(series_description):\n",
    "    return model_dics.get(series_description, None)\n",
    "\n",
    "# Function to make predictions on the test data\n",
    "def predict_test_data(testloader, expanded_test_desc):\n",
    "    predictions = []\n",
    "    normal_mild_probs = []\n",
    "    moderate_probs = []\n",
    "    severe_probs = []\n",
    "    \n",
    "    for model in model_dics.values():\n",
    "        model.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for idx, images in enumerate(tqdm(testloader)):\n",
    "            images = images.to(device)\n",
    "            series_description = expanded_test_desc.iloc[idx]['series_description']\n",
    "            model = get_model(series_description)\n",
    "            if model:\n",
    "                model.eval()  # Set the model to eval mode\n",
    "                outputs = model(images)\n",
    "                probs = torch.softmax(outputs, dim=1).squeeze(0)\n",
    "                normal_mild_probs.append(probs[0].item())\n",
    "                moderate_probs.append(probs[1].item())\n",
    "                severe_probs.append(probs[2].item())\n",
    "                predictions.append(probs)\n",
    "            else:\n",
    "                normal_mild_probs.append(None)\n",
    "                moderate_probs.append(None)\n",
    "                severe_probs.append(None)\n",
    "                predictions.append(None)\n",
    "    return normal_mild_probs, moderate_probs, severe_probs, predictions\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the test data\n",
    "normal_mild_probs, moderate_probs, severe_probs, test_predictions = predict_test_data(testloader, expanded_test_desc)\n",
    "\n",
    "# Add predictions and probabilities to the test DataFrame\n",
    "expanded_test_desc['normal_mild'] = normal_mild_probs\n",
    "expanded_test_desc['moderate'] = moderate_probs\n",
    "expanded_test_desc['severe'] = severe_probs\n",
    "\n",
    "submission = expanded_test_desc[[\"row_id\",\"normal_mild\",\"moderate\",\"severe\"]]\n",
    "\n",
    "# Group by 'row_id' and sum the values\n",
    "grouped_submission = submission.groupby('row_id').max().reset_index()\n",
    "\n",
    "# Normalize the columns\n",
    "grouped_submission[['normal_mild', 'moderate', 'severe']] = grouped_submission[['normal_mild', 'moderate', 'severe']].div(grouped_submission[['normal_mild', 'moderate', 'severe']].sum(axis=1), axis=0)\n",
    "\n",
    "print(grouped_submission)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "datasetId": 5227790,
     "sourceId": 8713880,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5228113,
     "sourceId": 8714321,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 105.278273,
   "end_time": "2024-06-17T17:24:43.355593",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-17T17:22:58.077320",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
