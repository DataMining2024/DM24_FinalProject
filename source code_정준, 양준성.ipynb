{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc852ae-50e4-435b-8ca2-bd81f44a1a77",
   "metadata": {},
   "source": [
    "# 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6c3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a8646",
   "metadata": {},
   "source": [
    "# 바꿀만한 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5685195",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 1\n",
    "margin = 10\n",
    "learning_rate = 0.005\n",
    "user_name = \"june16\"\n",
    "best_model_name = './weights/'+user_name+'sBERT_best.pth' \n",
    "last_model_name = './weights/'+user_name+'sBERT_last.pth'\n",
    "early_stop = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145e28b6-f256-4e04-bc01-cf3b273e5c87",
   "metadata": {},
   "source": [
    "# 학습 파라미터 및 loss 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1532ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilarityLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineSimilarityLoss, self).__init__()\n",
    "        self.cosine_sim = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        return margin * (1 - self.cosine_sim(x1, x2).mean()) # 0~1사이면 loss가 너무 적어 학습이 안될 수도 있으니 곱해주는 겁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b2d65c-797b-4682-9c66-cbecfbf17b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = \"cuda:0\"\n",
    "device = torch.device(gpu)\n",
    "criterion = CosineSimilarityLoss()\n",
    "seed = 42  # 랜덤시드 고정\n",
    "torch.manual_seed(seed)\n",
    "train_batch = 135"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed3bb5-6e5b-4c46-aa02-f7f91e3acb23",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0aeda49-fb66-4c3e-b252-fc6484d82f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/Images/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/Images/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/Images/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/Images/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/Images/1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image  \\\n",
       "0  ./data/Images/1000268201_693b08cb0e.jpg   \n",
       "1  ./data/Images/1000268201_693b08cb0e.jpg   \n",
       "2  ./data/Images/1000268201_693b08cb0e.jpg   \n",
       "3  ./data/Images/1000268201_693b08cb0e.jpg   \n",
       "4  ./data/Images/1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \n",
       "0  A child in a pink dress is climbing up a set o...  \n",
       "1              A girl going into a wooden building .  \n",
       "2   A little girl climbing into a wooden playhouse .  \n",
       "3  A little girl climbing the stairs to her playh...  \n",
       "4  A little girl in a pink dress going into a woo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")[['image','caption']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d095549d-125f-4551-b46a-68d1cf47b6b4",
   "metadata": {},
   "source": [
    "# Train, validation, Test split(60, 20, 20비율로) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f435d74d-8933-413e-aefb-b2d38d451d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.4, random_state=42)\n",
    "valid, test = train_test_split(test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f596d13-faf6-4012-a44f-847f6f2f590d",
   "metadata": {},
   "source": [
    "# 파이토치 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a3789a-34ee-48e7-bfdb-9dcd9c747e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flickr8k(Dataset):\n",
    "  def __init__(self,df):\n",
    "    super().__init__()\n",
    "    self.data = df.to_numpy().tolist()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    img, cap = self.data[index]\n",
    "    img = cv2.resize(cv2.imread(img),(320,320))\n",
    "    return {\"image\":img.transpose(2,0,1), \"caption\":cap}\n",
    "\n",
    "\n",
    "train_dataset = Flickr8k(train)\n",
    "valid_dataset = Flickr8k(valid)\n",
    "test_dataset = Flickr8k(test)\n",
    "del df\n",
    "num_cores = os.cpu_count()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch, shuffle=True,num_workers=num_cores)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=train_batch, shuffle=False,num_workers=num_cores)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=train_batch, shuffle=False,num_workers=num_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc7ac3-b3a6-47a0-b86b-df6a678f55d6",
   "metadata": {},
   "source": [
    "# 이미지 임베딩 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11211b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEmbedder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEmbedder, self).__init__()\n",
    "        # ResNet50 불러오기\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        # Backbone으로 활용하기 위해 last layer 제거.\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        # BERT의 Output과 차원을 맞추기 위해 mlp 추가\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768,384)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d142c9d-02f3-412d-9425-06e6eed37931",
   "metadata": {},
   "source": [
    "# 이미지 임베딩, BERT모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe76e45-e9ad-4a56-8448-1299fe2d32c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_embedder = ImageEmbedder().to(gpu)\n",
    "sentence_embedder = model = SentenceTransformer('paraphrase-MiniLM-L6-v2').to(gpu)\n",
    "model.eval()\n",
    "sentence_embedder.eval()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e147e-5962-45d4-ad6c-8dc4d6892185",
   "metadata": {},
   "source": [
    "# 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b147d59b-6820-4326-afb9-b9e707f9765d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start\n",
      "시작 시간: 2024-06-20 14:41:39.183439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:1] train_loss: 7.21859 val_loss: 7.03393 best!\n",
      "종료 시간: 2024-06-20 14:44:32.023485\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(image_embedder.parameters(), lr=learning_rate) # 경사하강법을 바꾸는 방법도...?\n",
    "best = float(\"inf\")\n",
    "print(\"train start\")\n",
    "current_time = datetime.now()\n",
    "early_stop_cnt = 0\n",
    "print(\"시작 시간:\", current_time)\n",
    "for epoch in range(num_epoch):\n",
    "    train_mse = 0\n",
    "    val_loss = 0\n",
    "    image_embedder.train()\n",
    "    pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), leave=False)\n",
    "    for idx, batch in pbar:\n",
    "        pbar.set_postfix(cos=margin-(train_mse/max(1,idx)))\n",
    "        img, cap = batch['image'].float().to(gpu), batch['caption']\n",
    "        img = image_embedder(img)\n",
    "        with torch.no_grad():\n",
    "            cap = torch.Tensor(model.encode(cap)).to(gpu)\n",
    "        loss = criterion(img, cap)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_mse += loss.item()\n",
    "        \n",
    "        del img, cap, batch, loss\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "    train_mse /= len(train_dataloader)\n",
    "    del pbar\n",
    "    image_embedder.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar2 = tqdm(enumerate(valid_dataloader), total=len(valid_dataloader), leave=False)\n",
    "        for idx, batch in pbar2:\n",
    "            pbar2.set_postfix(cos=margin-(val_loss/max(1,idx)))\n",
    "            img, cap = batch['image'].float().to(gpu), batch['caption']\n",
    "            img = image_embedder(img)\n",
    "            cap = torch.Tensor(model.encode(cap)).to(gpu)\n",
    "            val_loss += criterion(img, cap).item()\n",
    "            del img, cap, batch\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        val_loss /= len(valid_dataloader)\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"[epoch:{epoch+1}] train_loss: {train_mse:.5f} val_loss: {val_loss:.5f}\", end= \" \")\n",
    "        if val_loss < best:\n",
    "            print('best!')\n",
    "            torch.save(image_embedder.state_dict(), best_model_name)\n",
    "            best = val_loss\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            print()\n",
    "            early_stop_cnt += 1\n",
    "        del pbar2\n",
    "    torch.save(image_embedder.state_dict(), last_model_name)\n",
    "    if early_stop_cnt >= early_stop:\n",
    "        print(\"early stop!\")\n",
    "        break\n",
    "current_time = datetime.now()\n",
    "print(\"종료 시간:\", current_time)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7176fb",
   "metadata": {},
   "source": [
    "# 데이터베이스에 이미지 다 올리기(Test데이터만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2691d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_embedder.load_state_dict(torch.load(best_model_name))\n",
    "image_embedder.eval()\n",
    "with torch.no_grad():\n",
    "    pbar2 = tqdm(enumerate(test_dataloader), total=len(test_dataloader), leave=False)\n",
    "    first=True\n",
    "    for idx, batch in pbar2:\n",
    "        img = batch['image'].float().to(gpu)\n",
    "        img = image_embedder(img)\n",
    "        cap = batch['caption']\n",
    "        cap = torch.Tensor(model.encode(cap)).to(\"cuda:1\")\n",
    "        if first:\n",
    "            first=False\n",
    "            database = img\n",
    "            database = database.to(\"cuda:1\")\n",
    "            text_database = cap\n",
    "            text_database = text_database.to(\"cuda:1\")\n",
    "        else:\n",
    "            img = img.to(\"cuda:1\")\n",
    "            database = torch.cat((database,img),dim=0)\n",
    "            text_database = torch.cat((text_database,cap),dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21725ad4",
   "metadata": {},
   "source": [
    "# Hit Rate 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "829c74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_for_topk = [1,5, 10, 20, 30, 50, 75, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e120a2",
   "metadata": {},
   "source": [
    "# Hit Rate(자연어 -> 이미지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "930730e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@1: 0.02%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@5: 0.25%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@10: 0.42%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@20: 0.96%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@30: 1.20%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@50: 2.10%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@75: 3.35%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@100: 4.36%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for hit_k in k_for_topk:\n",
    "        hit_rate = 0\n",
    "        for idx in tqdm(range(len(test)),leave=False):\n",
    "            cap = torch.Tensor(model.encode(list(test[['caption']].iloc[idx])))\n",
    "            cap = cap.to(\"cuda:1\")\n",
    "            distance = F.cosine_similarity(cap, database)\n",
    "            distance = distance.view(-1, 1).T\n",
    "            _, indices = torch.topk(distance, hit_k)\n",
    "            if idx in indices:\n",
    "                hit_rate += 1\n",
    "            del cap, distance, indices\n",
    "        print(f\"Hit@{hit_k}: {(hit_rate/len(test))*100:.2f}%\")\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2953e6",
   "metadata": {},
   "source": [
    "# Hit Rate (이미지 -> 이미지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec7284cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@1: 66.58%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@5: 99.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@10: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@20: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@30: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@50: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@75: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@100: 100.00%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for hit_k in k_for_topk:\n",
    "        hit_rate = 0\n",
    "        for idx in tqdm(range(len(test)),leave=False):\n",
    "            img = cv2.resize(cv2.imread(list(test[['image']].iloc[idx])[0]),(320,320)).transpose(2,0,1)\n",
    "            img = torch.Tensor(img).unsqueeze(0).float().to(\"cuda:0\")\n",
    "            img = image_embedder(img).to(\"cuda:1\")\n",
    "            distance = F.cosine_similarity(img, database)\n",
    "            distance = distance.view(-1, 1).T\n",
    "            _, indices = torch.topk(distance, hit_k)\n",
    "            if idx in indices:\n",
    "                hit_rate += 1\n",
    "        print(f\"Hit@{hit_k}: {(hit_rate/len(test))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d82ba8",
   "metadata": {},
   "source": [
    "# Hit Rate (이미지 -> 자연어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81407430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@1: 4.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@5: 4.71%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@10: 4.73%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@20: 4.73%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@30: 4.75%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@50: 4.75%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@75: 4.75%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@100: 4.75%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for hit_k in k_for_topk:\n",
    "        hit_rate = 0\n",
    "        for idx in tqdm(range(len(test)),leave=False):\n",
    "            img = cv2.resize(cv2.imread(list(test[['image']].iloc[idx])[0]),(320,320)).transpose(2,0,1)\n",
    "            img = torch.Tensor(img).unsqueeze(0).float().to(\"cuda:0\")\n",
    "            img = image_embedder(img).to(\"cuda:1\")\n",
    "            distance = F.cosine_similarity(img, text_database)\n",
    "            distance = distance.view(-1, 1).T\n",
    "            _, indices = torch.topk(text_database, hit_k)\n",
    "            if idx in indices:\n",
    "                hit_rate += 1\n",
    "        print(f\"Hit@{hit_k}: {(hit_rate/len(test))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65c9df",
   "metadata": {},
   "source": [
    "# 속도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91607276",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ffe908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1, query process time(avg): 5.91 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 5, query process time(avg): 6.08 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 10, query process time(avg): 5.36 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 20, query process time(avg): 6.12 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 50, query process time(avg): 5.20 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 100, query process time(avg): 5.13 ms\n"
     ]
    }
   ],
   "source": [
    "database = database.T.to(\"cuda:1\")\n",
    "for hit_k in [1, 5, 10, 20, 50, 100]:\n",
    "    speed = 0\n",
    "    for idx in tqdm(range(len(test)),leave=False):\n",
    "        inp = list(test[['caption']].iloc[idx])\n",
    "        s = time.time()\n",
    "        cap = torch.Tensor(model.encode(inp)).to(\"cuda:1\")\n",
    "        distance = torch.matmul(cap,database)\n",
    "        _, indices = torch.topk(distance, hit_k)\n",
    "        e = time.time()\n",
    "        speed += ( e - s )\n",
    "    print(f\"K: {hit_k}, query process time(avg): {1000 * (speed / len(test)):.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d0c4e",
   "metadata": {},
   "source": [
    "# MRR(자연어 -> 이미지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mrr_scores = []\n",
    "    for idx in tqdm(range(len(test)), leave=False):\n",
    "        query_caption = torch.Tensor(model.encode([test['caption'].iloc[idx]])).to(\"cuda:1\")\n",
    "        distances = F.cosine_similarity(query_caption, database)\n",
    "        _, indices = torch.topk(distances, len(test), largest=True)\n",
    "        true_idx = indices == idx\n",
    "        rank = (true_idx.nonzero(as_tuple=True)[0] + 1).float()\n",
    "        if rank.nelement() > 0:\n",
    "            mrr_scores.append(1.0 / rank.item())\n",
    "        else:\n",
    "            mrr_scores.append(0)\n",
    "    mean_mrr = np.mean(mrr_scores)\n",
    "    print(f\"MRR (Text to Image): {mean_mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff86bb8c",
   "metadata": {},
   "source": [
    "# MRR (이미지 -> 이미지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f5305",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mrr_scores = []\n",
    "    for idx in tqdm(range(len(test)), leave=False):\n",
    "        query_image_path = test['image'].iloc[idx]\n",
    "        query_image = cv2.resize(cv2.imread(query_image_path), (320, 320)).transpose(2,0,1)\n",
    "        query_image = torch.Tensor(query_image).unsqueeze(0).float().to(\"cuda:0\")\n",
    "        query_image = image_embedder(query_image).to(\"cuda:1\")\n",
    "        distances = F.cosine_similarity(query_image, database)\n",
    "        _, indices = torch.topk(distances, len(test), largest=True)\n",
    "        true_idx = indices == idx\n",
    "        rank = (true_idx.nonzero(as_tuple=True)[0] + 1).float()\n",
    "        if rank.nelement() > 0:\n",
    "            mrr_scores.append(1.0 / rank.item())\n",
    "        else:\n",
    "            mrr_scores.append(0)\n",
    "    mean_mrr = np.mean(mrr_scores)\n",
    "    print(f\"MRR (Image to Image): {mean_mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7198a4ef",
   "metadata": {},
   "source": [
    "# MRR (이미지 -> 자연어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mrr_scores = []\n",
    "    for idx in tqdm(range(len(test)), leave=False):\n",
    "        query_image_path = test['image'].iloc[idx]\n",
    "        query_image = cv2.resize(cv2.imread(query_image_path), (320, 320)).transpose(2,0,1)\n",
    "        query_image = torch.Tensor(query_image).unsqueeze(0).float().to(\"cuda:0\")\n",
    "        query_image = image_embedder(query_image).to(\"cuda:1\")\n",
    "        distances = F.cosine_similarity(query_image, text_database)\n",
    "        _, indices = torch.topk(distances, len(test), largest=True)\n",
    "        true_idx = indices == idx\n",
    "        rank = (true_idx.nonzero(as_tuple=True)[0] + 1).float()\n",
    "        if rank.nelement() > 0:\n",
    "            mrr_scores.append(1.0 / rank.item())\n",
    "        else:\n",
    "            mrr_scores.append(0)\n",
    "    mean_mrr = np.mean(mrr_scores)\n",
    "    print(f\"MRR (Image to Text): {mean_mrr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
